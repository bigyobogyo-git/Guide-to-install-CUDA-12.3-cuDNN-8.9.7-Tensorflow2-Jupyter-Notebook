{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f706957d-60f5-4682-96db-8c3fdbb99a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.legacy.image_classification import augment\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4511323-f898-437d-a405-a2ae5f650790",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "\n",
    "CROP_TO = 72\n",
    "RESIZE_TO = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2907e3af-76f9-4417-aa44-426f6f31128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "val_samples = 49500\n",
    "new_train_x, new_y_train = x_train[: val_samples + 1], y_train[: val_samples + 1]\n",
    "val_x, val_y = x_train[val_samples:], y_train[val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a100e91-adb5-4915-8d0e-790f93f0dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize `RandAugment` object with 2 layers of\n",
    "# augmentation transforms and strength of 9.\n",
    "augmenter = augment.RandAugment(num_layers=2, magnitude=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5622f683-997f-4385-8ea6-af0f568b011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 16:38:42.338412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.374876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.376830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.380114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.381479: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.382804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.523948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.524896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.525828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 16:38:42.526589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8750 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def preprocess_train(image, label, noisy=True):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # We first resize the original image to a larger dimension\n",
    "    # and then we take random crops from it.\n",
    "    image = tf.image.resize(image, [RESIZE_TO, RESIZE_TO])\n",
    "    image = tf.image.random_crop(image, [CROP_TO, CROP_TO, 3])\n",
    "    if noisy:\n",
    "        image = augmenter.distort(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def preprocess_test(image, label):\n",
    "    image = tf.image.resize(image, [CROP_TO, CROP_TO])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((new_train_x, new_y_train))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65905dba-3310-41ab-88f3-7a4fe8f3e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset will be used to train the first model.\n",
    "train_clean_ds = (\n",
    "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
    "    .map(lambda x, y: (preprocess_train(x, y, noisy=False)), num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# This prepares the `Dataset` object to use RandAugment.\n",
    "train_noisy_ds = (\n",
    "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
    "    .map(preprocess_train, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validation_ds = (\n",
    "    validation_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    test_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# This dataset will be used to train the second model.\n",
    "consistency_training_ds = tf.data.Dataset.zip((train_clean_ds, train_noisy_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77aeb59-594c-4cec-b84d-ce2f52deead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images, sample_labels = next(iter(train_clean_ds))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "sample_images, sample_labels = next(iter(train_noisy_ds))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "658f9c86-4f5c-4d75-bf34-455e9df339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_model(num_classes=10):\n",
    "    resnet50_v2 = tf.keras.applications.ResNet50V2(\n",
    "        weights=None, include_top=False, input_shape=(CROP_TO, CROP_TO, 3),\n",
    "    )\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.Input((CROP_TO, CROP_TO, 3)),\n",
    "            layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "            resnet50_v2,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(num_classes),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43920b76-ea58-4fd2-9ae0-e6207512ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_teacher_model = get_training_model()\n",
    "initial_teacher_model.save_weights(\"initial_teacher_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05d9a483-754d-4f2d-bb45-28c4a1d8fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 16:42:32.066293: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 58s 124ms/step - loss: 1.6025 - accuracy: 0.4239 - val_loss: 1.6182 - val_accuracy: 0.4560 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "387/387 [==============================] - 50s 128ms/step - loss: 1.2259 - accuracy: 0.5608 - val_loss: 1.4097 - val_accuracy: 0.5360 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "387/387 [==============================] - 49s 125ms/step - loss: 1.0413 - accuracy: 0.6320 - val_loss: 1.6785 - val_accuracy: 0.5280 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "387/387 [==============================] - 49s 126ms/step - loss: 0.9197 - accuracy: 0.6766 - val_loss: 1.2162 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "387/387 [==============================] - 50s 128ms/step - loss: 0.8168 - accuracy: 0.7163 - val_loss: 0.8677 - val_accuracy: 0.6840 - lr: 0.0010\n",
      "Test accuracy: 67.58999824523926%\n"
     ]
    }
   ],
   "source": [
    "# Define the callbacks.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Initialize SWA from tf-hub.\n",
    "SWA = tfa.optimizers.SWA\n",
    "\n",
    "# Compile and train the teacher model.\n",
    "teacher_model = get_training_model()\n",
    "teacher_model.load_weights(\"initial_teacher_model.h5\")\n",
    "teacher_model.compile(\n",
    "    # Notice that we are wrapping our optimizer within SWA\n",
    "    optimizer=SWA(tf.keras.optimizers.legacy.Adam()),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = teacher_model.fit(\n",
    "    train_clean_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the teacher model on the test set.\n",
    "_, acc = teacher_model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test accuracy: {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5989fb7-8289-44d3-ab1b-2af29718839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority of the code is taken from:\n",
    "# https://keras.io/examples/vision/knowledge_distillation/\n",
    "class SelfTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "\n",
    "    def compile(\n",
    "        self, optimizer, metrics, student_loss_fn, distillation_loss_fn, temperature=3,\n",
    "    ):\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Since our dataset is a zip of two independent datasets,\n",
    "        # after initially parsing them, we segregate the\n",
    "        # respective images and labels next.\n",
    "        clean_ds, noisy_ds = data\n",
    "        clean_images, _ = clean_ds\n",
    "        noisy_images, y = noisy_ds\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(clean_images, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(noisy_images, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            total_loss = (student_loss + distillation_loss) / 2\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`\n",
    "        self.compiled_metrics.update_state(\n",
    "            y, tf.nn.softmax(student_predictions, axis=1)\n",
    "        )\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"total_loss\": total_loss})\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # During inference, we only pass a dataset consisting images and labels.\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(y, tf.nn.softmax(y_prediction, axis=1))\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93e0ddb4-f4d2-44b4-b9ef-aecc4223f783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 16:46:52.519933: I external/local_xla/xla/service/service.cc:168] XLA service 0x7b164479eec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-31 16:46:52.519949: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-10-31 16:46:52.523266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761925612.573043   27769 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 72s 152ms/step - accuracy: 0.2653 - total_loss: 1.0381 - val_accuracy: 0.3980 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "387/387 [==============================] - 62s 160ms/step - accuracy: 0.3572 - total_loss: 0.9148 - val_accuracy: 0.4740 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "387/387 [==============================] - 62s 161ms/step - accuracy: 0.4068 - total_loss: 0.8551 - val_accuracy: 0.4620 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "387/387 [==============================] - 62s 161ms/step - accuracy: 0.4351 - total_loss: 0.8198 - val_accuracy: 0.5340 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "387/387 [==============================] - 62s 161ms/step - accuracy: 0.4684 - total_loss: 0.7796 - val_accuracy: 0.5680 - lr: 0.0010\n",
      "Test accuracy from student model: 57.45000243186951%\n"
     ]
    }
   ],
   "source": [
    "# Define the callbacks.\n",
    "# We are using a larger decay factor to stabilize the training.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=3, factor=0.5, monitor=\"val_accuracy\"\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "# Compile and train the student model.\n",
    "self_trainer = SelfTrainer(student=get_training_model(), teacher=teacher_model)\n",
    "self_trainer.compile(\n",
    "    # Notice we are *not* using SWA here.\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "    temperature=10,\n",
    ")\n",
    "history = self_trainer.fit(\n",
    "    consistency_training_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the student model.\n",
    "acc = self_trainer.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test accuracy from student model: {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e408e0-c1ba-4f93-8638-9373d05f7910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce6037-d131-42f2-be52-e40de8d69494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca1d55-2517-4994-8fa7-99c567ddc1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7bdc2-851a-4cc0-823e-d76528a863e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123cab29-149b-436a-a5b8-e6512d6aea4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06460ef1-ffb1-44fd-bca3-d25ef1934343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215411d-4e5d-48cb-bb61-40ed0b4f6867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09585234-c7cd-4fb0-9ca5-d069c63fd393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9f5b3-1951-41f5-8b09-2bc59c45afd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f50d1e-45c9-44c2-b03c-4f2dc61087c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227697b3-57f1-473f-bccb-1e862fa8cce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

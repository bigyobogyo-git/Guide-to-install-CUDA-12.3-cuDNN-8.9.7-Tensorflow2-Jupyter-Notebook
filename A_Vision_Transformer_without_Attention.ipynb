{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9051d4de-92c4-4956-9364-001230e71df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:41:05.258475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "# Setting seed for reproducibiltiy\n",
    "SEED = 42\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6120bd77-05ab-4f42-b82b-92ee7ce3ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    # DATA\n",
    "    batch_size = 10\n",
    "    buffer_size = batch_size * 2\n",
    "    input_shape = (32, 32, 3)\n",
    "    num_classes = 10\n",
    "\n",
    "    # AUGMENTATION\n",
    "    image_size = 48\n",
    "\n",
    "    # ARCHITECTURE\n",
    "    patch_size = 4\n",
    "    projected_dim = 96\n",
    "    num_shift_blocks_per_stages = [2, 4, 8, 2]\n",
    "    epsilon = 1e-5\n",
    "    stochastic_depth_rate = 0.2\n",
    "    mlp_dropout_rate = 0.2\n",
    "    num_div = 12\n",
    "    shift_pixel = 1\n",
    "    mlp_expand_ratio = 2\n",
    "\n",
    "    # OPTIMIZER\n",
    "    lr_start = 1e-5\n",
    "    lr_max = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    # TRAINING\n",
    "    epochs = 100\n",
    "\n",
    "    # INFERENCE\n",
    "    label_map = {\n",
    "        0: \"airplane\",\n",
    "        1: \"automobile\",\n",
    "        2: \"bird\",\n",
    "        3: \"cat\",\n",
    "        4: \"deer\",\n",
    "        5: \"dog\",\n",
    "        6: \"frog\",\n",
    "        7: \"horse\",\n",
    "        8: \"ship\",\n",
    "        9: \"truck\",\n",
    "    }\n",
    "    tf_ds_batch_size = 20\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596b5cc0-27c0-414b-ae06-c2769742364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 40000\n",
      "Validation samples: 10000\n",
      "Testing samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761129672.773358    9318 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_val, y_val) = (\n",
    "    (x_train[:40000], y_train[:40000]),\n",
    "    (x_train[40000:], y_train[40000:]),\n",
    ")\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Validation samples: {len(x_val)}\")\n",
    "print(f\"Testing samples: {len(x_test)}\")\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(config.buffer_size).batch(config.batch_size).prefetch(AUTO)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.batch(config.batch_size).prefetch(AUTO)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.batch(config.batch_size).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f9e764-cb98-4436-a252-610096f3eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_model():\n",
    "    \"\"\"Build the data augmentation model.\"\"\"\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Resizing(config.input_shape[0] + 20, config.input_shape[0] + 20),\n",
    "            layers.RandomCrop(config.image_size, config.image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.Rescaling(1 / 255.0),\n",
    "        ]\n",
    "    )\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d446cb4d-65fc-47d2-98b6-0932b9476fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(layers.Layer):\n",
    "    \"\"\"Get the MLP layer for each shift block.\n",
    "\n",
    "    Args:\n",
    "        mlp_expand_ratio (int): The ratio with which the first feature map is expanded.\n",
    "        mlp_dropout_rate (float): The rate for dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mlp_expand_ratio, mlp_dropout_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_channels = input_shape[-1]\n",
    "        initial_filters = int(self.mlp_expand_ratio * input_channels)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(\n",
    "                    units=initial_filters,\n",
    "                    activation=\"gelu\",\n",
    "                ),\n",
    "                layers.Dropout(rate=self.mlp_dropout_rate),\n",
    "                layers.Dense(units=input_channels),\n",
    "                layers.Dropout(rate=self.mlp_dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6830f719-f653-46e8-8a46-60c1d4391f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(layers.Layer):\n",
    "    \"\"\"Drop Path also known as the Stochastic Depth layer.\n",
    "\n",
    "    Refernece:\n",
    "        - https://keras.io/examples/vision/cct/#stochastic-depth-for-regularization\n",
    "        - github.com:rwightman/pytorch-image-models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_path_prob, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_path_prob\n",
    "            shape = (ops.shape(x)[0],) + (1,) * (len(ops.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + keras.random.uniform(\n",
    "                shape, 0, 1, seed=self.seed_generator\n",
    "            )\n",
    "            random_tensor = ops.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b720f4-4023-4420-b6f4-1ce3e16d14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftViTBlock(layers.Layer):\n",
    "    \"\"\"A unit ShiftViT Block\n",
    "\n",
    "    Args:\n",
    "        shift_pixel (int): The number of pixels to shift. Default to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which MLP features are\n",
    "            expanded. Default to 2.\n",
    "        mlp_dropout_rate (float): The dropout rate used in MLP.\n",
    "        num_div (int): The number of divisions of the feature map's channel.\n",
    "            Totally, 4/num_div of channels will be shifted. Defaults to 12.\n",
    "        epsilon (float): Epsilon constant.\n",
    "        drop_path_prob (float): The drop probability for drop path.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon,\n",
    "        drop_path_prob,\n",
    "        mlp_dropout_rate,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.shift_pixel = shift_pixel\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "        self.num_div = num_div\n",
    "        self.epsilon = epsilon\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "        self.C = input_shape[3]\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.drop_path = (\n",
    "            DropPath(drop_path_prob=self.drop_path_prob)\n",
    "            if self.drop_path_prob > 0.0\n",
    "            else layers.Activation(\"linear\")\n",
    "        )\n",
    "        self.mlp = MLP(\n",
    "            mlp_expand_ratio=self.mlp_expand_ratio,\n",
    "            mlp_dropout_rate=self.mlp_dropout_rate,\n",
    "        )\n",
    "\n",
    "    def get_shift_pad(self, x, mode):\n",
    "        \"\"\"Shifts the channels according to the mode chosen.\"\"\"\n",
    "        if mode == \"left\":\n",
    "            offset_height = 0\n",
    "            offset_width = 0\n",
    "            target_height = 0\n",
    "            target_width = self.shift_pixel\n",
    "        elif mode == \"right\":\n",
    "            offset_height = 0\n",
    "            offset_width = self.shift_pixel\n",
    "            target_height = 0\n",
    "            target_width = self.shift_pixel\n",
    "        elif mode == \"up\":\n",
    "            offset_height = 0\n",
    "            offset_width = 0\n",
    "            target_height = self.shift_pixel\n",
    "            target_width = 0\n",
    "        else:\n",
    "            offset_height = self.shift_pixel\n",
    "            offset_width = 0\n",
    "            target_height = self.shift_pixel\n",
    "            target_width = 0\n",
    "        crop = ops.image.crop_images(\n",
    "            x,\n",
    "            top_cropping=offset_height,\n",
    "            left_cropping=offset_width,\n",
    "            target_height=self.H - target_height,\n",
    "            target_width=self.W - target_width,\n",
    "        )\n",
    "        shift_pad = ops.image.pad_images(\n",
    "            crop,\n",
    "            top_padding=offset_height,\n",
    "            left_padding=offset_width,\n",
    "            target_height=self.H,\n",
    "            target_width=self.W,\n",
    "        )\n",
    "        return shift_pad\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        # Split the feature maps\n",
    "        x_splits = ops.split(x, indices_or_sections=self.C // self.num_div, axis=-1)\n",
    "\n",
    "        # Shift the feature maps\n",
    "        x_splits[0] = self.get_shift_pad(x_splits[0], mode=\"left\")\n",
    "        x_splits[1] = self.get_shift_pad(x_splits[1], mode=\"right\")\n",
    "        x_splits[2] = self.get_shift_pad(x_splits[2], mode=\"up\")\n",
    "        x_splits[3] = self.get_shift_pad(x_splits[3], mode=\"down\")\n",
    "\n",
    "        # Concatenate the shifted and unshifted feature maps\n",
    "        x = ops.concatenate(x_splits, axis=-1)\n",
    "\n",
    "        # Add the residual connection\n",
    "        shortcut = x\n",
    "        x = shortcut + self.drop_path(self.mlp(self.layer_norm(x)), training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f43851-1802-4ad8-ae83-34c1503d8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(layers.Layer):\n",
    "    \"\"\"The Patch Merging layer.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): The epsilon constant.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        filters = 2 * input_shape[-1]\n",
    "        self.reduction = layers.Conv2D(\n",
    "            filters=filters, kernel_size=2, strides=2, padding=\"same\", use_bias=False\n",
    "        )\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=self.epsilon)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply the patch merging algorithm on the feature maps\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3588d7e-2d9c-4ace-b768-921705d5a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This layer will have a different depth of stacking\n",
    "# for different stages on the model.\n",
    "class StackedShiftBlocks(layers.Layer):\n",
    "    \"\"\"The layer containing stacked ShiftViTBlocks.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): The epsilon constant.\n",
    "        mlp_dropout_rate (float): The dropout rate used in the MLP block.\n",
    "        num_shift_blocks (int): The number of shift vit blocks for this stage.\n",
    "        stochastic_depth_rate (float): The maximum drop path rate chosen.\n",
    "        is_merge (boolean): A flag that determines the use of the Patch Merge\n",
    "            layer after the shift vit blocks.\n",
    "        num_div (int): The division of channels of the feature map. Defaults to 12.\n",
    "        shift_pixel (int): The number of pixels to shift. Defaults to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which the initial dense layer of\n",
    "            the MLP is expanded Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon,\n",
    "        mlp_dropout_rate,\n",
    "        num_shift_blocks,\n",
    "        stochastic_depth_rate,\n",
    "        is_merge,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "        self.num_shift_blocks = num_shift_blocks\n",
    "        self.stochastic_depth_rate = stochastic_depth_rate\n",
    "        self.is_merge = is_merge\n",
    "        self.num_div = num_div\n",
    "        self.shift_pixel = shift_pixel\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        # Calculate stochastic depth probabilities.\n",
    "        # Reference: https://keras.io/examples/vision/cct/#the-final-cct-model\n",
    "        dpr = [\n",
    "            x\n",
    "            for x in np.linspace(\n",
    "                start=0, stop=self.stochastic_depth_rate, num=self.num_shift_blocks\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Build the shift blocks as a list of ShiftViT Blocks\n",
    "        self.shift_blocks = list()\n",
    "        for num in range(self.num_shift_blocks):\n",
    "            self.shift_blocks.append(\n",
    "                ShiftViTBlock(\n",
    "                    num_div=self.num_div,\n",
    "                    epsilon=self.epsilon,\n",
    "                    drop_path_prob=dpr[num],\n",
    "                    mlp_dropout_rate=self.mlp_dropout_rate,\n",
    "                    shift_pixel=self.shift_pixel,\n",
    "                    mlp_expand_ratio=self.mlp_expand_ratio,\n",
    "                )\n",
    "            )\n",
    "        if self.is_merge:\n",
    "            self.patch_merge = PatchMerging(epsilon=self.epsilon)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        for shift_block in self.shift_blocks:\n",
    "            x = shift_block(x, training=training)\n",
    "        if self.is_merge:\n",
    "            x = self.patch_merge(x)\n",
    "        return x\n",
    "\n",
    "    # Since this is a custom layer, we need to overwrite get_config()\n",
    "    # so that model can be easily saved & loaded after training\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"epsilon\": self.epsilon,\n",
    "                \"mlp_dropout_rate\": self.mlp_dropout_rate,\n",
    "                \"num_shift_blocks\": self.num_shift_blocks,\n",
    "                \"stochastic_depth_rate\": self.stochastic_depth_rate,\n",
    "                \"is_merge\": self.is_merge,\n",
    "                \"num_div\": self.num_div,\n",
    "                \"shift_pixel\": self.shift_pixel,\n",
    "                \"mlp_expand_ratio\": self.mlp_expand_ratio,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad0c158-1e2d-44a1-9206-80ae044c77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftViTModel(keras.Model):\n",
    "    \"\"\"The ShiftViT Model.\n",
    "\n",
    "    Args:\n",
    "        data_augmentation (keras.Model): A data augmentation model.\n",
    "        projected_dim (int): The dimension to which the patches of the image are\n",
    "            projected.\n",
    "        patch_size (int): The patch size of the images.\n",
    "        num_shift_blocks_per_stages (list[int]): A list of all the number of shit\n",
    "            blocks per stage.\n",
    "        epsilon (float): The epsilon constant.\n",
    "        mlp_dropout_rate (float): The dropout rate used in the MLP block.\n",
    "        stochastic_depth_rate (float): The maximum drop rate probability.\n",
    "        num_div (int): The number of divisions of the channesl of the feature\n",
    "            map. Defaults to 12.\n",
    "        shift_pixel (int): The number of pixel to shift. Default to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which the initial mlp dense layer\n",
    "            is expanded to. Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_augmentation,\n",
    "        projected_dim,\n",
    "        patch_size,\n",
    "        num_shift_blocks_per_stages,\n",
    "        epsilon,\n",
    "        mlp_dropout_rate,\n",
    "        stochastic_depth_rate,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.patch_projection = layers.Conv2D(\n",
    "            filters=projected_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.stages = list()\n",
    "        for index, num_shift_blocks in enumerate(num_shift_blocks_per_stages):\n",
    "            if index == len(num_shift_blocks_per_stages) - 1:\n",
    "                # This is the last stage, do not use the patch merge here.\n",
    "                is_merge = False\n",
    "            else:\n",
    "                is_merge = True\n",
    "            # Build the stages.\n",
    "            self.stages.append(\n",
    "                StackedShiftBlocks(\n",
    "                    epsilon=epsilon,\n",
    "                    mlp_dropout_rate=mlp_dropout_rate,\n",
    "                    num_shift_blocks=num_shift_blocks,\n",
    "                    stochastic_depth_rate=stochastic_depth_rate,\n",
    "                    is_merge=is_merge,\n",
    "                    num_div=num_div,\n",
    "                    shift_pixel=shift_pixel,\n",
    "                    mlp_expand_ratio=mlp_expand_ratio,\n",
    "                )\n",
    "            )\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling2D()\n",
    "\n",
    "        self.classifier = layers.Dense(config.num_classes)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"data_augmentation\": self.data_augmentation,\n",
    "                \"patch_projection\": self.patch_projection,\n",
    "                \"stages\": self.stages,\n",
    "                \"global_avg_pool\": self.global_avg_pool,\n",
    "                \"classifier\": self.classifier,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def _calculate_loss(self, data, training=True):\n",
    "        (images, labels) = data\n",
    "\n",
    "        # Augment the images\n",
    "        augmented_images = self.data_augmentation(images, training=training)\n",
    "\n",
    "        # Create patches and project the pathces.\n",
    "        projected_patches = self.patch_projection(augmented_images)\n",
    "\n",
    "        # Pass through the stages\n",
    "        x = projected_patches\n",
    "        for stage in self.stages:\n",
    "            x = stage(x, training=training)\n",
    "\n",
    "        # Get the logits.\n",
    "        x = self.global_avg_pool(x)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        # Calculate the loss and return it.\n",
    "        total_loss = self.compiled_loss(labels, logits)\n",
    "        return total_loss, labels, logits\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, labels, logits = self._calculate_loss(\n",
    "                data=inputs, training=True\n",
    "            )\n",
    "\n",
    "        # Apply gradients.\n",
    "        train_vars = [\n",
    "            self.data_augmentation.trainable_variables,\n",
    "            self.patch_projection.trainable_variables,\n",
    "            self.global_avg_pool.trainable_variables,\n",
    "            self.classifier.trainable_variables,\n",
    "        ]\n",
    "        train_vars = train_vars + [stage.trainable_variables for stage in self.stages]\n",
    "\n",
    "        # Optimize the gradients.\n",
    "        grads = tape.gradient(total_loss, train_vars)\n",
    "        trainable_variable_list = []\n",
    "        for (grad, var) in zip(grads, train_vars):\n",
    "            for g, v in zip(grad, var):\n",
    "                trainable_variable_list.append((g, v))\n",
    "        self.optimizer.apply_gradients(trainable_variable_list)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(labels, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        _, labels, logits = self._calculate_loss(data=data, training=True)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(labels, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, images):\n",
    "        augmented_images = self.data_augmentation(images)\n",
    "        x = self.patch_projection(augmented_images)\n",
    "        for stage in self.stages:\n",
    "            x = stage(x, training=True)\n",
    "        x = self.global_avg_pool(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64291d23-a0f5-40a2-b418-31c0270cd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShiftViTModel(\n",
    "    data_augmentation=get_augmentation_model(),\n",
    "    projected_dim=config.projected_dim,\n",
    "    patch_size=config.patch_size,\n",
    "    num_shift_blocks_per_stages=config.num_shift_blocks_per_stages,\n",
    "    epsilon=config.epsilon,\n",
    "    mlp_dropout_rate=config.mlp_dropout_rate,\n",
    "    stochastic_depth_rate=config.stochastic_depth_rate,\n",
    "    num_div=config.num_div,\n",
    "    shift_pixel=config.shift_pixel,\n",
    "    mlp_expand_ratio=config.mlp_expand_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2c0c15-3da0-40e7-8e1e-70c0a8208b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code is taken from:\n",
    "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"A LearningRateSchedule that uses a warmup cosine decay schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, lr_start, lr_max, warmup_steps, total_steps):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lr_start: The initial learning rate\n",
    "            lr_max: The maximum learning rate to which lr should increase to in\n",
    "                the warmup steps\n",
    "            warmup_steps: The number of steps for which the model warms up\n",
    "            total_steps: The total number of steps for the model training\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.pi = ops.array(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Check whether the total number of steps is larger than the warmup\n",
    "        # steps. If not, then throw a value error.\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\n",
    "                f\"Total number of steps {self.total_steps} must be\"\n",
    "                + f\"larger or equal to warmup steps {self.warmup_steps}.\"\n",
    "            )\n",
    "\n",
    "        # `cos_annealed_lr` is a graph that increases to 1 from the initial\n",
    "        # step to the warmup step. After that this graph decays to -1 at the\n",
    "        # final step mark.\n",
    "        cos_annealed_lr = ops.cos(\n",
    "            self.pi\n",
    "            * (ops.cast(step, dtype=\"float32\") - self.warmup_steps)\n",
    "            / ops.cast(self.total_steps - self.warmup_steps, dtype=\"float32\")\n",
    "        )\n",
    "\n",
    "        # Shift the mean of the `cos_annealed_lr` graph to 1. Now the grpah goes\n",
    "        # from 0 to 2. Normalize the graph with 0.5 so that now it goes from 0\n",
    "        # to 1. With the normalized graph we scale it with `lr_max` such that\n",
    "        # it goes from 0 to `lr_max`\n",
    "        learning_rate = 0.5 * self.lr_max * (1 + cos_annealed_lr)\n",
    "\n",
    "        # Check whether warmup_steps is more than 0.\n",
    "        if self.warmup_steps > 0:\n",
    "            # Check whether lr_max is larger that lr_start. If not, throw a value\n",
    "            # error.\n",
    "            if self.lr_max < self.lr_start:\n",
    "                raise ValueError(\n",
    "                    f\"lr_start {self.lr_start} must be smaller or\"\n",
    "                    + f\"equal to lr_max {self.lr_max}.\"\n",
    "                )\n",
    "\n",
    "            # Calculate the slope with which the learning rate should increase\n",
    "            # in the warumup schedule. The formula for slope is m = ((b-a)/steps)\n",
    "            slope = (self.lr_max - self.lr_start) / self.warmup_steps\n",
    "\n",
    "            # With the formula for a straight line (y = mx+c) build the warmup\n",
    "            # schedule\n",
    "            warmup_rate = slope * ops.cast(step, dtype=\"float32\") + self.lr_start\n",
    "\n",
    "            # When the current step is lesser that warmup steps, get the line\n",
    "            # graph. When the current step is greater than the warmup steps, get\n",
    "            # the scaled cos graph.\n",
    "            learning_rate = ops.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "\n",
    "        # When the current step is more that the total steps, return 0 else return\n",
    "        # the calculated graph.\n",
    "        return ops.where(step > self.total_steps, 0.0, learning_rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"lr_start\": self.lr_start,\n",
    "            \"lr_max\": self.lr_max,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "        }\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ae81b9-0f1b-4bef-bd0f-936174ba67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:41:16.090260: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xy/Desktop/ml/keras/test/keras_test/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:671: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n",
      "/home/xy/Desktop/ml/keras/test/keras_test/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:646: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n",
      "E0000 00:00:1761129689.075038    9318 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/stacked_shift_blocks_1/shift_vi_t_block_1/mlp_1/sequential_1_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3999/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1706 - top-5-accuracy: 0.6280 - loss: 0.0949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761129848.345326    9318 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/stacked_shift_blocks_1/shift_vi_t_block_1/mlp_1/sequential_1_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 41ms/step - accuracy: 0.1707 - top-5-accuracy: 0.6280 - loss: 0.0948 - val_loss: 0.0556\n",
      "Epoch 2/100\n",
      "\u001b[1m   5/4000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 37ms/step - accuracy: 0.3667 - top-5-accuracy: 0.8527 - loss: 0.0540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xy/Desktop/ml/keras/test/keras_test/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,top-5-accuracy,loss,val_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.3756 - top-5-accuracy: 0.8741 - loss: 0.0091 - val_loss: 0.2855\n",
      "Epoch 3/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.4374 - top-5-accuracy: 0.9066 - loss: 0.1245 - val_loss: 0.0843\n",
      "Epoch 4/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.4873 - top-5-accuracy: 0.9288 - loss: 0.2865 - val_loss: 0.5690\n",
      "Epoch 5/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.5157 - top-5-accuracy: 0.9376 - loss: 0.5348 - val_loss: 0.7062\n",
      "Epoch 6/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.5399 - top-5-accuracy: 0.9425 - loss: 0.6805 - val_loss: 0.6521\n",
      "Epoch 7/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.5665 - top-5-accuracy: 0.9487 - loss: 0.5580 - val_loss: 0.3316\n",
      "Epoch 8/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.5802 - top-5-accuracy: 0.9551 - loss: 0.3408 - val_loss: 0.1558\n",
      "Epoch 9/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.5957 - top-5-accuracy: 0.9574 - loss: 0.1792 - val_loss: 0.1127\n",
      "Epoch 10/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.6148 - top-5-accuracy: 0.9615 - loss: 0.0874 - val_loss: 0.2310\n",
      "Epoch 11/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.6273 - top-5-accuracy: 0.9653 - loss: 0.0019 - val_loss: 0.0515\n",
      "Epoch 12/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.6365 - top-5-accuracy: 0.9673 - loss: -0.0760 - val_loss: -0.0641\n",
      "Epoch 13/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.6538 - top-5-accuracy: 0.9687 - loss: -0.1003 - val_loss: -0.0893\n",
      "Epoch 14/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.6579 - top-5-accuracy: 0.9725 - loss: -0.1064 - val_loss: -0.0392\n",
      "Epoch 15/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.6651 - top-5-accuracy: 0.9722 - loss: -0.1053 - val_loss: -0.0111\n",
      "Epoch 16/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.6796 - top-5-accuracy: 0.9747 - loss: -0.0884 - val_loss: -0.0391\n",
      "Epoch 17/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.6916 - top-5-accuracy: 0.9756 - loss: -0.0829 - val_loss: -0.0879\n",
      "Epoch 18/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7011 - top-5-accuracy: 0.9789 - loss: -0.0843 - val_loss: -0.0541\n",
      "Epoch 19/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7113 - top-5-accuracy: 0.9802 - loss: -0.0847 - val_loss: -0.0409\n",
      "Epoch 20/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7184 - top-5-accuracy: 0.9817 - loss: -0.0775 - val_loss: -0.1033\n",
      "Epoch 21/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7259 - top-5-accuracy: 0.9827 - loss: -0.0901 - val_loss: -0.1349\n",
      "Epoch 22/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7379 - top-5-accuracy: 0.9841 - loss: -0.1010 - val_loss: -0.0652\n",
      "Epoch 23/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7410 - top-5-accuracy: 0.9848 - loss: -0.0948 - val_loss: -0.0564\n",
      "Epoch 24/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7491 - top-5-accuracy: 0.9847 - loss: -0.1110 - val_loss: -0.1133\n",
      "Epoch 25/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7534 - top-5-accuracy: 0.9859 - loss: -0.1142 - val_loss: -0.0294\n",
      "Epoch 26/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7537 - top-5-accuracy: 0.9868 - loss: -0.0855 - val_loss: -0.1207\n",
      "Epoch 27/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7679 - top-5-accuracy: 0.9873 - loss: -0.1177 - val_loss: -0.0965\n",
      "Epoch 28/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 42ms/step - accuracy: 0.7740 - top-5-accuracy: 0.9889 - loss: -0.1077 - val_loss: -0.0952\n",
      "Epoch 29/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7735 - top-5-accuracy: 0.9880 - loss: -0.1122 - val_loss: -0.1303\n",
      "Epoch 30/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7794 - top-5-accuracy: 0.9888 - loss: -0.1184 - val_loss: -0.1195\n",
      "Epoch 31/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7808 - top-5-accuracy: 0.9903 - loss: -0.1058 - val_loss: -0.1157\n",
      "Epoch 32/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7864 - top-5-accuracy: 0.9897 - loss: -0.1032 - val_loss: -0.0583\n",
      "Epoch 33/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7930 - top-5-accuracy: 0.9912 - loss: -0.1188 - val_loss: -0.1034\n",
      "Epoch 34/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.7979 - top-5-accuracy: 0.9918 - loss: -0.1143 - val_loss: -0.0542\n",
      "Epoch 35/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.7971 - top-5-accuracy: 0.9915 - loss: -0.1044 - val_loss: -0.1159\n",
      "Epoch 36/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8032 - top-5-accuracy: 0.9925 - loss: -0.1317 - val_loss: -0.0733\n",
      "Epoch 37/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8107 - top-5-accuracy: 0.9931 - loss: -0.1114 - val_loss: -0.1409\n",
      "Epoch 38/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8083 - top-5-accuracy: 0.9930 - loss: -0.1270 - val_loss: -0.1211\n",
      "Epoch 39/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8136 - top-5-accuracy: 0.9933 - loss: -0.1264 - val_loss: -0.1268\n",
      "Epoch 40/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8186 - top-5-accuracy: 0.9941 - loss: -0.1288 - val_loss: -0.1202\n",
      "Epoch 41/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.8223 - top-5-accuracy: 0.9940 - loss: -0.1268 - val_loss: -0.2098\n",
      "Epoch 42/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 43ms/step - accuracy: 0.8245 - top-5-accuracy: 0.9940 - loss: -0.1440 - val_loss: -0.1206\n",
      "Epoch 43/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 44ms/step - accuracy: 0.8292 - top-5-accuracy: 0.9946 - loss: -0.1465 - val_loss: -0.1328\n",
      "Epoch 44/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 45ms/step - accuracy: 0.8258 - top-5-accuracy: 0.9953 - loss: -0.1552 - val_loss: -0.1945\n",
      "Epoch 45/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 46ms/step - accuracy: 0.8380 - top-5-accuracy: 0.9961 - loss: -0.1688 - val_loss: -0.2211\n",
      "Epoch 46/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 46ms/step - accuracy: 0.8400 - top-5-accuracy: 0.9953 - loss: -0.1566 - val_loss: -0.1444\n",
      "Epoch 47/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 47ms/step - accuracy: 0.8405 - top-5-accuracy: 0.9956 - loss: -0.1616 - val_loss: -0.1737\n",
      "Epoch 48/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 45ms/step - accuracy: 0.8444 - top-5-accuracy: 0.9958 - loss: -0.1559 - val_loss: -0.1879\n",
      "Epoch 49/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 46ms/step - accuracy: 0.8484 - top-5-accuracy: 0.9954 - loss: -0.1776 - val_loss: -0.1536\n",
      "Epoch 50/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 46ms/step - accuracy: 0.8483 - top-5-accuracy: 0.9957 - loss: -0.1732 - val_loss: -0.1820\n",
      "Epoch 51/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 44ms/step - accuracy: 0.8568 - top-5-accuracy: 0.9961 - loss: -0.1854 - val_loss: -0.1965\n",
      "Epoch 52/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.8594 - top-5-accuracy: 0.9970 - loss: -0.1962 - val_loss: -0.0543\n",
      "Epoch 53/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8586 - top-5-accuracy: 0.9971 - loss: -0.1784 - val_loss: -0.1796\n",
      "Epoch 54/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8648 - top-5-accuracy: 0.9975 - loss: -0.1804 - val_loss: -0.2240\n",
      "Epoch 55/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 44ms/step - accuracy: 0.8668 - top-5-accuracy: 0.9968 - loss: -0.2011 - val_loss: -0.2530\n",
      "Epoch 56/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 44ms/step - accuracy: 0.8707 - top-5-accuracy: 0.9974 - loss: -0.1920 - val_loss: -0.1867\n",
      "Epoch 57/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 44ms/step - accuracy: 0.8719 - top-5-accuracy: 0.9976 - loss: -0.1946 - val_loss: -0.1949\n",
      "Epoch 58/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 44ms/step - accuracy: 0.8737 - top-5-accuracy: 0.9979 - loss: -0.1987 - val_loss: -0.1678\n",
      "Epoch 59/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.8822 - top-5-accuracy: 0.9975 - loss: -0.2006 - val_loss: -0.1792\n",
      "Epoch 60/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.8833 - top-5-accuracy: 0.9974 - loss: -0.2082 - val_loss: -0.2412\n",
      "Epoch 61/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8833 - top-5-accuracy: 0.9980 - loss: -0.2118 - val_loss: -0.1537\n",
      "Epoch 62/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8892 - top-5-accuracy: 0.9981 - loss: -0.2082 - val_loss: -0.2028\n",
      "Epoch 63/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8902 - top-5-accuracy: 0.9983 - loss: -0.1861 - val_loss: -0.2151\n",
      "Epoch 64/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8908 - top-5-accuracy: 0.9981 - loss: -0.1853 - val_loss: -0.1676\n",
      "Epoch 65/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8978 - top-5-accuracy: 0.9986 - loss: -0.1941 - val_loss: -0.1815\n",
      "Epoch 66/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8987 - top-5-accuracy: 0.9988 - loss: -0.1981 - val_loss: -0.1508\n",
      "Epoch 67/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.8968 - top-5-accuracy: 0.9988 - loss: -0.2287 - val_loss: -0.2647\n",
      "Epoch 68/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.9047 - top-5-accuracy: 0.9988 - loss: -0.2331 - val_loss: -0.2700\n",
      "Epoch 69/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.9049 - top-5-accuracy: 0.9988 - loss: -0.2103 - val_loss: -0.1572\n",
      "Epoch 70/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.9070 - top-5-accuracy: 0.9986 - loss: -0.2102 - val_loss: -0.2414\n",
      "Epoch 71/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.9079 - top-5-accuracy: 0.9983 - loss: -0.2427 - val_loss: -0.2284\n",
      "Epoch 72/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 41ms/step - accuracy: 0.9134 - top-5-accuracy: 0.9988 - loss: -0.2347 - val_loss: -0.2562\n",
      "Epoch 73/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9155 - top-5-accuracy: 0.9988 - loss: -0.2255 - val_loss: -0.2279\n",
      "Epoch 74/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9136 - top-5-accuracy: 0.9989 - loss: -0.2680 - val_loss: -0.2200\n",
      "Epoch 75/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9170 - top-5-accuracy: 0.9988 - loss: -0.2549 - val_loss: -0.2603\n",
      "Epoch 76/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9210 - top-5-accuracy: 0.9992 - loss: -0.2479 - val_loss: -0.2346\n",
      "Epoch 77/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9233 - top-5-accuracy: 0.9995 - loss: -0.2553 - val_loss: -0.2566\n",
      "Epoch 78/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.9223 - top-5-accuracy: 0.9991 - loss: -0.2816 - val_loss: -0.2472\n",
      "Epoch 79/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9266 - top-5-accuracy: 0.9992 - loss: -0.2751 - val_loss: -0.2519\n",
      "Epoch 80/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 42ms/step - accuracy: 0.9258 - top-5-accuracy: 0.9991 - loss: -0.2993 - val_loss: -0.2940\n",
      "Epoch 81/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 42ms/step - accuracy: 0.9264 - top-5-accuracy: 0.9993 - loss: -0.2874 - val_loss: -0.2866\n",
      "Epoch 82/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 43ms/step - accuracy: 0.9289 - top-5-accuracy: 0.9991 - loss: -0.3052 - val_loss: -0.3118\n",
      "Epoch 83/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 44ms/step - accuracy: 0.9287 - top-5-accuracy: 0.9993 - loss: -0.2994 - val_loss: -0.3196\n",
      "Epoch 84/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 43ms/step - accuracy: 0.9331 - top-5-accuracy: 0.9996 - loss: -0.3175 - val_loss: -0.2824\n",
      "Epoch 85/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 43ms/step - accuracy: 0.9323 - top-5-accuracy: 0.9994 - loss: -0.3068 - val_loss: -0.2901\n",
      "Epoch 86/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 44ms/step - accuracy: 0.9359 - top-5-accuracy: 0.9995 - loss: -0.3248 - val_loss: -0.2958\n",
      "Epoch 87/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 44ms/step - accuracy: 0.9348 - top-5-accuracy: 0.9996 - loss: -0.3239 - val_loss: -0.3220\n",
      "Epoch 88/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.9345 - top-5-accuracy: 0.9995 - loss: -0.3117 - val_loss: -0.2964\n",
      "Epoch 89/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 44ms/step - accuracy: 0.9388 - top-5-accuracy: 0.9991 - loss: -0.3065 - val_loss: -0.3229\n",
      "Epoch 90/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 44ms/step - accuracy: 0.9383 - top-5-accuracy: 0.9993 - loss: -0.3317 - val_loss: -0.3194\n",
      "Epoch 91/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.9380 - top-5-accuracy: 0.9991 - loss: -0.3322 - val_loss: -0.3241\n",
      "Epoch 92/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 43ms/step - accuracy: 0.9368 - top-5-accuracy: 0.9992 - loss: -0.3304 - val_loss: -0.3324\n",
      "Epoch 93/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 43ms/step - accuracy: 0.9385 - top-5-accuracy: 0.9993 - loss: -0.3488 - val_loss: -0.3356\n",
      "Epoch 94/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 43ms/step - accuracy: 0.9372 - top-5-accuracy: 0.9994 - loss: -0.3430 - val_loss: -0.3504\n",
      "Epoch 95/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 47ms/step - accuracy: 0.9397 - top-5-accuracy: 0.9990 - loss: -0.3435 - val_loss: -0.3499\n",
      "Epoch 96/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 47ms/step - accuracy: 0.9386 - top-5-accuracy: 0.9993 - loss: -0.3510 - val_loss: -0.3342\n",
      "Epoch 97/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 45ms/step - accuracy: 0.9455 - top-5-accuracy: 0.9992 - loss: -0.3407 - val_loss: -0.3430\n",
      "Epoch 98/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 44ms/step - accuracy: 0.9404 - top-5-accuracy: 0.9996 - loss: -0.3436 - val_loss: -0.3372\n",
      "Epoch 99/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 43ms/step - accuracy: 0.9386 - top-5-accuracy: 0.9994 - loss: -0.3423 - val_loss: -0.3389\n",
      "Epoch 100/100\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 43ms/step - accuracy: 0.9424 - top-5-accuracy: 0.9993 - loss: -0.3453 - val_loss: -0.3406\n",
      "TESTING\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7717 - top-5-accuracy: 0.9854 - loss: -0.3461\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Evaluate the model with the test dataset.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTESTING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m loss, acc_top1, acc_top5 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 1 test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_top1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# pass sample data to the model so that input shape is available at the time of\n",
    "# saving the model\n",
    "sample_ds, _ = next(iter(train_ds))\n",
    "model(sample_ds, training=True)\n",
    "\n",
    "# Get the total number of steps for training.\n",
    "total_steps = int((len(x_train) / config.batch_size) * config.epochs)\n",
    "\n",
    "# Calculate the number of steps for warmup.\n",
    "warmup_epoch_percentage = 0.15\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "\n",
    "# Initialize the warmupcosine schedule.\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    lr_start=1e-5,\n",
    "    lr_max=1e-3,\n",
    "    warmup_steps=warmup_steps,\n",
    "    total_steps=total_steps,\n",
    ")\n",
    "\n",
    "# Get the optimizer.\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=scheduled_lrs, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# Compile and pretrain the model.\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=config.epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\",\n",
    "            patience=5,\n",
    "            mode=\"auto\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Evaluate the model with the test dataset.\n",
    "print(\"TESTING\")\n",
    "loss, acc_top1, acc_top5 = model.evaluate(test_ds)\n",
    "print(f\"Loss: {loss:0.2f}\")\n",
    "print(f\"Top 1 test accuracy: {acc_top1*100:0.2f}%\")\n",
    "print(f\"Top 5 test accuracy: {acc_top5*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ff82c-8a7e-49cd-9c45-5b544b246f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782510e-5172-4187-9855-376bc3e9780c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a135e99-906a-48ad-b2ee-e2a9404aae52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5a636-b291-4ab3-80bb-655de5089450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d9275-957b-4cd8-b943-05ff714435ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4da13f-2d3b-46e5-9e29-2a7eafb88a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa019a2-1dcc-4806-8e46-ff4749545bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3ca64-919d-4d81-8cf8-00ddaa9bd7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf6615-6815-4e26-94ce-6cbf803330dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfdbc09-9644-4ea6-bb2c-38c55eec529b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a7cf3-1059-443e-97c6-732375a46b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f993f-43a2-43eb-92e7-6de5ed093599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f1ad3-f522-4e1c-aa75-3c5c75c16072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc158228-adeb-4418-a3f8-d32884f03609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d666bd-c366-4acb-a671-3888cb5f3105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c075dfd-b1e1-4611-b5b7-29c91943059f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8fc5b-3d20-486e-8bdb-5fad0b7de084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc61c372-0dee-4346-8541-489764c59cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 15:06:49.922221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5edaf95-df24-48d2-9a01-16a8f3789c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04af4fb-484b-46cc-a30d-53d11ecc4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: 45000\n",
      "Validation data samples: 5000\n",
      "Test data samples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "val_split = 0.1\n",
    "\n",
    "val_indices = int(len(x_train) * val_split)\n",
    "new_x_train, new_y_train = x_train[val_indices:], y_train[val_indices:]\n",
    "x_val, y_val = x_train[:val_indices], y_train[:val_indices]\n",
    "\n",
    "print(f\"Training data samples: {len(new_x_train)}\")\n",
    "print(f\"Validation data samples: {len(x_val)}\")\n",
    "print(f\"Test data samples: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a0bf30-a186-4987-b5e9-8c31740e0cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 15:07:23.251947: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2025-10-20 15:07:23.251971: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-10-20 15:07:23.251975: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: xy\n",
      "2025-10-20 15:07:23.251977: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: xy\n",
      "2025-10-20 15:07:23.252077: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-10-20 15:07:23.252093: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.65.6\n",
      "2025-10-20 15:07:23.252095: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:287] kernel version 580.65.6 does not match DSO version 580.95.5 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "augmentation_layers = [\n",
    "    keras.layers.RandomCrop(image_size, image_size),\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "]\n",
    "\n",
    "\n",
    "def augment_images(images):\n",
    "    for layer in augmentation_layers:\n",
    "        images = layer(images, training=True)\n",
    "    return images\n",
    "\n",
    "\n",
    "def make_datasets(images, labels, is_train=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size * 10)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if is_train:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (augment_images(x), y), num_parallel_calls=auto\n",
    "        )\n",
    "    return dataset.prefetch(auto)\n",
    "\n",
    "\n",
    "train_dataset = make_datasets(new_x_train, new_y_train, is_train=True)\n",
    "val_dataset = make_datasets(x_val, y_val)\n",
    "test_dataset = make_datasets(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90936f3-8756-478b-ba95-c9767b5fa81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
